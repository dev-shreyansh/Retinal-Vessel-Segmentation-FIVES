{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# \ud83d\udd2c Retinal Blood Vessel Segmentation\n## FIVES Dataset \u00b7 U-Net \u00b7 PyTorch \u00b7 MPS Optimized\n\n**Fixes applied:** `tqdm.auto`, `num_workers=0`, MPS device, faster training config, deprecated API updates.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 1 \u2014 Device Check"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import platform, sys, torch\n\nprint(f\"\u2705 Running on: {platform.processor()}\")\nprint(f\"Python: {sys.version}\")\n\nif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\n    print(f\"\ud83d\ude80 CUDA GPU: {torch.cuda.get_device_name(0)}\")\nelif torch.backends.mps.is_available():\n    DEVICE = torch.device('mps')\n    print(\"\ud83d\ude80 Apple Silicon MPS enabled \u2014 GPU acceleration active!\")\nelse:\n    DEVICE = torch.device('cpu')\n    print(\"\u26a0\ufe0f  CPU only\")\n\nprint(f\"Device: {DEVICE}\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 2 \u2014 Download FIVES Dataset"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, zipfile, urllib.request\nfrom pathlib import Path\n\nDATA_DIR = Path('./archive')\nDATA_DIR.mkdir(exist_ok=True)\n\nFIVES_URL = 'https://figshare.com/ndownloader/articles/19688169/versions/1'\nZIP_PATH  = './archive.zip'\n\nif not (DATA_DIR / 'train').exists():\n    print('\u2b07\ufe0f  Downloading FIVES dataset (~1.2 GB)...')\n    def progress_hook(count, block_size, total_size):\n        pct = min(count * block_size * 100 / total_size, 100)\n        if count % 500 == 0:\n            print(f'   {pct:.1f}%', end='\\r')\n    urllib.request.urlretrieve(FIVES_URL, ZIP_PATH, progress_hook)\n    print('\\n\ud83d\udcc2 Extracting...')\n    with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n        z.extractall('./')\n    print('\u2705 FIVES dataset ready!')\nelse:\n    print('\u2705 FIVES already downloaded \u2014 skipping.')\n\nTRAIN_IMG_DIR  = DATA_DIR / 'train' / 'Original'\nTRAIN_MASK_DIR = DATA_DIR / 'train' / 'Ground truth'\nTEST_IMG_DIR   = DATA_DIR / 'test'  / 'Original'\nTEST_MASK_DIR  = DATA_DIR / 'test'  / 'Ground truth'\n\nfor d in [TRAIN_IMG_DIR, TRAIN_MASK_DIR, TEST_IMG_DIR, TEST_MASK_DIR]:\n    imgs = list(d.glob('*.png')) + list(d.glob('*.jpg'))\n    print(f'  {d}  \u2192  {len(imgs)} files')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 3 \u2014 EDA: CSV + Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import csv, random\nimport matplotlib.pyplot as plt\nimport cv2, numpy as np\nfrom collections import Counter\nfrom pathlib import Path\nimport os\n\nos.makedirs('./outputs', exist_ok=True)\n\nCATEGORIES = ['Normal', 'AMD', 'DR', 'Glaucoma']\ncat_map = {'N': 'Normal', 'A': 'AMD', 'D': 'DR', 'G': 'Glaucoma'}\n\nrows = []\nfor img_path in sorted(TRAIN_IMG_DIR.glob('*.png')) + sorted(TEST_IMG_DIR.glob('*.png')):\n    fname = img_path.name\n    # FIX: scan all chars for category letter (filenames may start with a digit)\n    prefix = next((c for c in fname.upper() if c in cat_map), None)\n    disease = cat_map.get(prefix, 'Unknown')\n    split = 'train' if 'train' in str(img_path) else 'test'\n    rows.append({'image': fname, 'mask': fname, 'disease': disease,\n                 'quality': 'Good', 'split': split})\n\nwith open('./outputs/fives_metadata.csv', 'w', newline='') as f:\n    writer = csv.DictWriter(f, fieldnames=['image','mask','disease','quality','split'])\n    writer.writeheader()\n    writer.writerows(rows)\nprint(f\"\u2705 CSV saved: {len(rows)} rows \u2192 ./outputs/fives_metadata.csv\")\n\ncounts = Counter(r['disease'] for r in rows)\nprint(\"\\n\ud83d\udcca Dataset counts per category:\")\nfor cat, n in counts.items():\n    print(f\"   {cat}: {n} images\")\n\n# Show 6 random image\u2013mask pairs\nimg_paths = sorted(TRAIN_IMG_DIR.glob('*.png'))\nchosen = random.sample(img_paths, 6)\nfig, axes = plt.subplots(2, 6, figsize=(18, 6))\nfig.suptitle('FIVES \u2014 6 Random Images + Ground Truth Masks', fontsize=14, fontweight='bold')\nfor i, ip in enumerate(chosen):\n    mp = TRAIN_MASK_DIR / ip.name\n    img  = cv2.cvtColor(cv2.imread(str(ip)), cv2.COLOR_BGR2RGB)\n    mask = cv2.imread(str(mp), cv2.IMREAD_GRAYSCALE)\n    img  = cv2.resize(img,  (256, 256))\n    mask = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n    axes[0,i].imshow(img);  axes[0,i].set_title(f'Image {i+1}', fontsize=9); axes[0,i].axis('off')\n    axes[1,i].imshow(mask, cmap='gray'); axes[1,i].set_title(f'Mask {i+1}', fontsize=9); axes[1,i].axis('off')\naxes[0,0].set_ylabel('Fundus Image', fontsize=10)\naxes[1,0].set_ylabel('Vessel Mask',  fontsize=10)\nplt.tight_layout()\nplt.savefig('./outputs/task1_image_mask_pairs.png', dpi=100, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Saved image\u2013mask pairs.\")\n\n# CLAHE comparison\nsample_img = cv2.cvtColor(cv2.imread(str(img_paths[0])), cv2.COLOR_BGR2RGB)\nsample_img = cv2.resize(sample_img, (512, 512))\nlab = cv2.cvtColor(sample_img, cv2.COLOR_RGB2LAB)\nclahe_op = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\nlab[:,:,0] = clahe_op.apply(lab[:,:,0])\nenhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\nfig, (a1, a2) = plt.subplots(1, 2, figsize=(10, 4))\na1.imshow(sample_img); a1.set_title('Original'); a1.axis('off')\na2.imshow(enhanced);   a2.set_title('After CLAHE'); a2.axis('off')\nplt.tight_layout()\nplt.savefig('./outputs/task2_clahe_comparison.png', dpi=100, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 CLAHE comparison saved.\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 4 \u2014 Configuration"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CFG = {\n    # Data \u2014 256px is ~4x faster than 512px with minimal accuracy loss\n    'image_size'      : 256,\n    'val_split'       : 0.1,\n    'num_workers'     : 0,          # FIX: 0 workers \u2014 macOS multiprocessing crash fix\n\n    # Model\n    'architecture'    : 'unet',\n    'encoder'         : 'resnet34',\n    'encoder_weights' : 'imagenet',\n\n    # Loss\n    'loss_type'       : 'combined',\n    'dice_w'          : 0.5,\n    'tversky_w'       : 0.3,\n    'focal_w'         : 0.2,\n    'tversky_alpha'   : 0.3,\n    'tversky_beta'    : 0.7,\n    'focal_gamma'     : 2.0,\n\n    # Training\n    'epochs'          : 50,\n    'batch_size'      : 16,\n    'lr'              : 2e-4,       # slightly higher LR for faster convergence\n    'weight_decay'    : 1e-4,\n    'early_stopping'  : 15,\n    'mixed_precision' : False,      # MPS doesn't support AMP \u2014 disabled\n    'grad_clip'       : 1.0,\n    'threshold'       : 0.5,\n\n    # Paths\n    'save_dir'        : './outputs',\n}\n\nimport os\nos.makedirs(CFG['save_dir'], exist_ok=True)\nprint('\u2705 Config ready.')\nprint(f\"   Arch: {CFG['architecture']} | Encoder: {CFG['encoder']}\")\nprint(f\"   Loss: {CFG['loss_type']} | Epochs: {CFG['epochs']} | Batch: {CFG['batch_size']}\")\nprint(f\"   Image size: {CFG['image_size']}\u00d7{CFG['image_size']} | Device: {DEVICE}\")\nprint(f\"   num_workers: {CFG['num_workers']} (0 = safe for macOS)\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 5 \u2014 Imports"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, glob, random, json, csv, time\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom pathlib import Path\nfrom tqdm.auto import tqdm            # FIX: tqdm.auto instead of tqdm.notebook\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch.amp import GradScaler, autocast  # FIX: updated import (non-deprecated)\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport segmentation_models_pytorch as smp\nfrom sklearn.metrics import roc_auc_score, roc_curve, matthews_corrcoef\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\nprint(f'\u2705 Imports done. Device: {DEVICE}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 6 \u2014 Dataset Class"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class FIVESDataset(Dataset):\n    def __init__(self, images_dir, masks_dir, transform=None,\n                 image_size=256, preprocess_clahe=True):\n        self.images_dir = images_dir\n        self.masks_dir  = masks_dir\n        self.transform  = transform\n        self.image_size = image_size\n        self.preprocess_clahe = preprocess_clahe\n\n        self.image_paths = sorted(\n            glob.glob(str(images_dir / '*.png')) +\n            glob.glob(str(images_dir / '*.jpg'))\n        )\n        if not self.image_paths:\n            raise FileNotFoundError(f'No images found in {images_dir}')\n\n        self.mask_paths = []\n        for img_path in self.image_paths:\n            fname     = os.path.basename(img_path)\n            mask_path = masks_dir / fname\n            if not mask_path.exists():\n                candidates = list(masks_dir.glob(f'{Path(fname).stem}.*'))\n                if candidates:\n                    mask_path = candidates[0]\n                else:\n                    raise FileNotFoundError(f'Mask not found for {img_path}')\n            self.mask_paths.append(str(mask_path))\n\n        print(f'  FIVESDataset | {len(self.image_paths)} samples from {images_dir.name}/')\n\n    @staticmethod\n    def apply_clahe(image_rgb):\n        lab = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2LAB)\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n        lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n        return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n\n    def _load_image(self, path):\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (self.image_size, self.image_size),\n                         interpolation=cv2.INTER_LINEAR)\n        return img\n\n    def _load_mask(self, path):\n        mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        mask = cv2.resize(mask, (self.image_size, self.image_size),\n                          interpolation=cv2.INTER_NEAREST)\n        return (mask > 127).astype(np.uint8)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = self._load_image(self.image_paths[idx])\n        mask  = self._load_mask(self.mask_paths[idx])\n        if self.preprocess_clahe:\n            image = self.apply_clahe(image)\n        if self.transform is not None:\n            aug   = self.transform(image=image, mask=mask)\n            image = aug['image']\n            mask  = aug['mask']\n        else:\n            image = torch.from_numpy(image).permute(2,0,1).float() / 255.0\n            mask  = torch.from_numpy(mask).unsqueeze(0).float()\n        if mask.dim() == 2:\n            mask = mask.unsqueeze(0)\n        return image, mask.float()\n\n\ndef get_train_transforms(size):\n    return A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.RandomRotate90(p=0.5),\n        A.Rotate(limit=30, border_mode=4, p=0.5),     # reduced rotation range for speed\n        A.ElasticTransform(alpha=60, sigma=6, p=0.2),  # lighter augmentation\n        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n        A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n        A.GaussNoise(p=0.2),                           # FIX: removed deprecated var_limit\n        A.Resize(size, size),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ])\n\ndef get_val_transforms(size):\n    return A.Compose([\n        A.Resize(size, size),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ])\n\n\ndef build_dataloaders(cfg):\n    size       = cfg['image_size']\n    val_split  = cfg['val_split']\n    batch_size = cfg['batch_size']\n    nw         = cfg['num_workers']   # FIX: 0 for macOS stability\n\n    full_train = FIVESDataset(\n        TRAIN_IMG_DIR, TRAIN_MASK_DIR,\n        transform=get_train_transforms(size),\n        image_size=size,\n    )\n    n_val   = max(1, int(len(full_train) * val_split))\n    n_train = len(full_train) - n_val\n    train_ds, val_ds = random_split(\n        full_train, [n_train, n_val],\n        generator=torch.Generator().manual_seed(SEED)\n    )\n    val_ds.dataset.transform = get_val_transforms(size)\n\n    test_ds = FIVESDataset(\n        TEST_IMG_DIR, TEST_MASK_DIR,\n        transform=get_val_transforms(size),\n        image_size=size,\n    )\n\n    # FIX: pin_memory=False \u2014 not supported on MPS\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n                              num_workers=nw, drop_last=True, pin_memory=False)\n    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n                              num_workers=nw, pin_memory=False)\n    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n                              num_workers=nw, pin_memory=False)\n\n    print(f'\\n\u2705 DataLoaders ready')\n    print(f'   Train: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(test_ds)}')\n    return train_loader, val_loader, test_loader, test_ds\n\n\nprint('\u2705 Dataset classes defined.')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 7 \u2014 Loss Functions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class DiceLoss(nn.Module):\n    def __init__(self, smooth=1.0):\n        super().__init__()\n        self.smooth = smooth\n    def forward(self, logits, targets):\n        probs   = torch.sigmoid(logits).view(-1)\n        targets = targets.view(-1)\n        inter   = (probs * targets).sum()\n        return 1 - (2*inter + self.smooth) / (probs.sum() + targets.sum() + self.smooth)\n\nclass TverskyLoss(nn.Module):\n    def __init__(self, alpha=0.3, beta=0.7, smooth=1.0):\n        super().__init__()\n        self.alpha, self.beta, self.smooth = alpha, beta, smooth\n    def forward(self, logits, targets):\n        probs   = torch.sigmoid(logits).view(-1)\n        targets = targets.view(-1)\n        tp = (probs * targets).sum()\n        fp = (probs * (1 - targets)).sum()\n        fn = ((1 - probs) * targets).sum()\n        return 1 - (tp + self.smooth) / (tp + self.alpha*fp + self.beta*fn + self.smooth)\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super().__init__()\n        self.alpha, self.gamma = alpha, gamma\n    def forward(self, logits, targets):\n        bce   = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n        probs = torch.sigmoid(logits)\n        p_t   = targets * probs + (1 - targets) * (1 - probs)\n        a_t   = targets * self.alpha + (1 - targets) * (1 - self.alpha)\n        return (a_t * (1 - p_t)**self.gamma * bce).mean()\n\nclass CombinedLoss(nn.Module):\n    def __init__(self, dice_w=0.5, tversky_w=0.3, focal_w=0.2,\n                 tversky_alpha=0.3, tversky_beta=0.7, focal_gamma=2.0):\n        super().__init__()\n        self.dice_w, self.tversky_w, self.focal_w = dice_w, tversky_w, focal_w\n        self.dice    = DiceLoss()\n        self.tversky = TverskyLoss(alpha=tversky_alpha, beta=tversky_beta)\n        self.focal   = FocalLoss(gamma=focal_gamma)\n    def forward(self, logits, targets):\n        return (self.dice_w    * self.dice(logits, targets) +\n                self.tversky_w * self.tversky(logits, targets) +\n                self.focal_w   * self.focal(logits, targets))\n\ndef build_loss(cfg):\n    t = cfg['loss_type']\n    if   t == 'dice'     : return DiceLoss()\n    elif t == 'bce_dice' : return nn.BCEWithLogitsLoss()\n    elif t == 'focal'    : return FocalLoss(gamma=cfg['focal_gamma'])\n    elif t == 'tversky'  : return TverskyLoss(alpha=cfg['tversky_alpha'], beta=cfg['tversky_beta'])\n    elif t == 'combined' :\n        return CombinedLoss(\n            dice_w=cfg['dice_w'], tversky_w=cfg['tversky_w'], focal_w=cfg['focal_w'],\n            tversky_alpha=cfg['tversky_alpha'], tversky_beta=cfg['tversky_beta'],\n            focal_gamma=cfg['focal_gamma'])\n    raise ValueError(f\"Unknown loss: {t}\")\n\nprint('\u2705 Loss functions defined.')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 8 \u2014 Model (U-Net via SMP)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def build_model(cfg):\n    arch   = cfg['architecture']\n    kwargs = dict(\n        encoder_name    = cfg['encoder'],\n        encoder_weights = cfg['encoder_weights'],\n        in_channels     = 3,\n        classes         = 1,\n        activation      = None,\n    )\n    if   arch == 'unet'          : model = smp.Unet(**kwargs)\n    elif arch == 'unetplusplus'  : model = smp.UnetPlusPlus(**kwargs)\n    elif arch == 'attention_unet': model = smp.Unet(**kwargs, decoder_attention_type='scse')\n    elif arch == 'manet'         : model = smp.MAnet(**kwargs)\n    else: raise ValueError(f'Unknown arch: {arch}')\n\n    n = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f'\u2705 Model: {arch} | Encoder: {cfg[\"encoder\"]} | Params: {n:,}')\n    return model\n\n# Quick sanity check\nmodel = build_model(CFG).to(DEVICE)\ndummy = torch.randn(2, 3, CFG['image_size'], CFG['image_size']).to(DEVICE)\nwith torch.no_grad():\n    out = model(dummy)\nprint(f'   Input : {dummy.shape}')\nprint(f'   Output: {out.shape}  \u2713')\ndel dummy, out\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 9 \u2014 Metrics"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compute_metrics(prob, target, threshold=0.5):\n    eps  = 1e-8\n    pred = (prob >= threshold).astype(bool)\n    gt   = target.astype(bool)\n    tp = (pred &  gt).sum()\n    fp = (pred & ~gt).sum()\n    fn = (~pred &  gt).sum()\n    tn = (~pred & ~gt).sum()\n    dice        = (2*tp + eps) / (2*tp + fp + fn + eps)\n    sensitivity = (tp + eps) / (tp + fn + eps)\n    specificity = (tn + eps) / (tn + fp + eps)\n    accuracy    = (tp + tn) / (tp + tn + fp + fn + eps)\n    try:    auc = float(roc_auc_score(target.astype(int), prob))\n    except: auc = 0.0\n    try:    mcc = float(matthews_corrcoef(target.astype(int), pred.astype(int)))\n    except: mcc = 0.0\n    return dict(dice=float(dice), auc_roc=float(auc),\n                sensitivity=float(sensitivity), specificity=float(specificity),\n                accuracy=float(accuracy), mcc=float(mcc))\n\ndef find_optimal_threshold(all_probs, all_targets):\n    fpr, tpr, thresholds = roc_curve(all_targets.astype(int), all_probs)\n    j = tpr - fpr\n    return float(thresholds[np.argmax(j)])\n\nprint('\u2705 Metrics defined.')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 10 \u2014 Training Loop"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_epoch(model, loader, optimizer, criterion, device, cfg):\n    model.train()\n    total_loss = 0.0\n    all_probs, all_targets = [], []\n\n    for images, masks in tqdm(loader, desc='  Train', leave=False):\n        images = images.to(device)\n        masks  = masks.to(device)\n        optimizer.zero_grad(set_to_none=True)\n\n        # FIX: no autocast on MPS (not supported); plain forward pass\n        logits = model(images)\n        loss   = criterion(logits, masks)\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), cfg['grad_clip'])\n        optimizer.step()\n\n        total_loss += loss.item()\n        with torch.no_grad():\n            all_probs.append(torch.sigmoid(logits).cpu().numpy().flatten())\n            all_targets.append(masks.cpu().numpy().flatten())\n\n    probs   = np.concatenate(all_probs)\n    targets = np.concatenate(all_targets)\n    m = compute_metrics(probs, targets)\n    m['loss'] = total_loss / len(loader)\n    return m\n\n\n@torch.no_grad()\ndef val_epoch(model, loader, criterion, device, cfg):\n    model.eval()\n    total_loss = 0.0\n    all_probs, all_targets = [], []\n\n    for images, masks in tqdm(loader, desc='  Val  ', leave=False):\n        images = images.to(device)\n        masks  = masks.to(device)\n        logits = model(images)\n        loss   = criterion(logits, masks)\n        total_loss += loss.item()\n        all_probs.append(torch.sigmoid(logits).cpu().numpy().flatten())\n        all_targets.append(masks.cpu().numpy().flatten())\n\n    probs   = np.concatenate(all_probs)\n    targets = np.concatenate(all_targets)\n    thresh  = find_optimal_threshold(probs, targets)\n    m = compute_metrics(probs, targets, threshold=thresh)\n    m['loss']      = total_loss / len(loader)\n    m['threshold'] = thresh\n    return m\n\n\ndef run_training(cfg):\n    train_loader, val_loader, test_loader, test_ds = build_dataloaders(cfg)\n\n    model     = build_model(cfg).to(DEVICE)\n    criterion = build_loss(cfg)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg['lr'],\n                                  weight_decay=cfg['weight_decay'])\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=cfg['epochs'], eta_min=1e-7)\n\n    # FIX: GradScaler updated API; disabled on MPS (not supported)\n    # scaler left out entirely since mixed_precision=False on MPS\n\n    save_dir  = Path(cfg['save_dir'])\n    best_ckpt = save_dir / 'best_model.pth'\n    history   = {'train_loss':[], 'val_loss':[], 'train_dice':[], 'val_dice':[]}\n    best_dice = 0.0\n    best_thresh = 0.5\n    no_improve  = 0\n\n    print(f\"\\n{'='*60}\")\n    print(f\"  Training: {cfg['architecture']} + {cfg['encoder']}\")\n    print(f\"  Epochs: {cfg['epochs']} | Batch: {cfg['batch_size']} | LR: {cfg['lr']}\")\n    print(f\"  Loss: {cfg['loss_type']} | Device: {DEVICE}\")\n    print(f\"  Image size: {cfg['image_size']}\u00d7{cfg['image_size']}\")\n    print(f\"{'='*60}\\n\")\n\n    for epoch in range(1, cfg['epochs'] + 1):\n        t0 = time.time()\n        train_m = train_epoch(model, train_loader, optimizer, criterion, DEVICE, cfg)\n        val_m   = val_epoch(model, val_loader, criterion, DEVICE, cfg)\n        scheduler.step()\n\n        elapsed = time.time() - t0\n        lr_now  = optimizer.param_groups[0]['lr']\n\n        print(\n            f\"Ep [{epoch:03d}/{cfg['epochs']}] \"\n            f\"Train Loss={train_m['loss']:.4f} Dice={train_m['dice']:.4f} | \"\n            f\"Val Loss={val_m['loss']:.4f} Dice={val_m['dice']:.4f} \"\n            f\"AUC={val_m['auc_roc']:.4f} Sens={val_m['sensitivity']:.4f} \"\n            f\"Spec={val_m['specificity']:.4f} Thr={val_m['threshold']:.3f} \"\n            f\"LR={lr_now:.2e} [{elapsed:.0f}s]\"\n        )\n\n        history['train_loss'].append(train_m['loss'])\n        history['val_loss'].append(val_m['loss'])\n        history['train_dice'].append(train_m['dice'])\n        history['val_dice'].append(val_m['dice'])\n\n        if val_m['dice'] > best_dice:\n            best_dice   = val_m['dice']\n            best_thresh = val_m['threshold']\n            no_improve  = 0\n            torch.save({\n                'epoch'           : epoch,\n                'model_state_dict': model.state_dict(),\n                'best_dice'       : best_dice,\n                'threshold'       : best_thresh,\n                'val_metrics'     : val_m,\n                'cfg'             : cfg,\n            }, best_ckpt)\n            print(f'  \u2705 New best! Dice={best_dice:.4f}  Threshold={best_thresh:.3f}')\n        else:\n            no_improve += 1\n            if no_improve >= cfg['early_stopping']:\n                print(f'\\n\u26d4 Early stopping at epoch {epoch}')\n                break\n\n    print(f\"\\n{'='*60}\")\n    print(f'  Training complete! Best Val Dice: {best_dice:.4f}')\n    print(f\"{'='*60}\\n\")\n    return model, history, test_loader, test_ds, best_thresh\n\n\nprint('\u2705 Training loop defined.')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 11 \u2014 \ud83d\ude80 Run Training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Quick test toggle \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nQUICK_TEST = True   # \u2190 Set False for full 50-epoch training\n\nif QUICK_TEST:\n    print('\u26a1 QUICK TEST MODE \u2014 5 epochs only')\n    CFG['epochs']         = 5\n    CFG['early_stopping'] = 99\n\nmodel, history, test_loader, test_ds, best_threshold = run_training(CFG)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 12 \u2014 Training Curves"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "epochs_ran = range(1, len(history['train_loss']) + 1)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n\nax1.plot(epochs_ran, history['train_loss'], label='Train Loss', color='steelblue', lw=2)\nax1.plot(epochs_ran, history['val_loss'],   label='Val Loss',   color='tomato',    lw=2)\nax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss')\nax1.set_title('Loss Curve'); ax1.legend(); ax1.grid(alpha=0.3)\n\nax2.plot(epochs_ran, history['train_dice'], label='Train Dice', color='steelblue', lw=2)\nax2.plot(epochs_ran, history['val_dice'],   label='Val Dice',   color='tomato',    lw=2)\nax2.axhline(0.82, linestyle='--', color='green', alpha=0.7, label='Target (0.82)')\nax2.set_xlabel('Epoch'); ax2.set_ylabel('Dice Score')\nax2.set_title('Dice Score Curve'); ax2.legend(); ax2.grid(alpha=0.3)\n\nplt.suptitle('Training History \u2014 FIVES Retinal Vessel Segmentation', fontsize=13, y=1.02)\nplt.tight_layout()\nplt.savefig(f\"{CFG['save_dir']}/training_curves.png\", dpi=150, bbox_inches='tight')\nplt.show()\nprint('\u2705 Training curves saved.')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 13 \u2014 Test Set Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@torch.no_grad()\ndef evaluate_test_set(model, test_loader, threshold, device, cfg):\n    model.eval()\n    all_probs, all_targets = [], []\n\n    for images, masks in tqdm(test_loader, desc='Evaluating test set'):\n        images = images.to(device)\n        logits = model(images)\n        probs  = torch.sigmoid(logits).cpu().numpy().flatten()\n        all_probs.append(probs)\n        all_targets.append(masks.numpy().flatten())\n\n    all_probs   = np.concatenate(all_probs)\n    all_targets = np.concatenate(all_targets)\n    metrics     = compute_metrics(all_probs, all_targets, threshold)\n\n    print(f\"\\n{'='*55}\")\n    print(f\"  FIVES Test Set \u2014 Final Results  (threshold={threshold:.3f})\")\n    print(f\"{'='*55}\")\n    rows = [\n        ('Dice Score',  metrics['dice'],        0.82, '\u2265 0.82'),\n        ('AUC-ROC',     metrics['auc_roc'],     0.98, '\u2265 0.98'),\n        ('Sensitivity', metrics['sensitivity'], 0.80, '\u2265 0.80'),\n        ('Specificity', metrics['specificity'], 0.97, '\u2265 0.97'),\n        ('MCC',         metrics['mcc'],         None, ''),\n        ('Accuracy',    metrics['accuracy'],    None, ''),\n    ]\n    for name, val, target, label in rows:\n        passed = '\u2705' if (target is None or val >= target) else '\u274c'\n        bar    = f\"(target {label})\" if label else ''\n        print(f\"  {passed} {name:<14}: {val:.4f}  {bar}\")\n\n    # FIX: all() takes a single iterable, not multiple args\n    all_pass = all([\n        metrics['dice'] >= 0.82,\n        metrics['auc_roc'] >= 0.98,\n        metrics['sensitivity'] >= 0.80,\n        metrics['specificity'] >= 0.97,\n    ])\n    print(f\"{'='*55}\")\n    print(f\"  PRD Criteria: {'\u2705 ALL PASSED' if all_pass else '\u274c Train more epochs'}\")\n    print(f\"{'='*55}\\n\")\n    return metrics, all_probs, all_targets\n\n\n# Load best checkpoint\nbest_ckpt_path = f\"{CFG['save_dir']}/best_model.pth\"\nckpt = torch.load(best_ckpt_path, map_location=DEVICE)\nmodel.load_state_dict(ckpt['model_state_dict'])\nbest_threshold = ckpt.get('threshold', CFG['threshold'])\nprint(f'\u2705 Loaded best model (epoch {ckpt[\"epoch\"]}, val Dice={ckpt[\"best_dice\"]:.4f})')\n\ntest_metrics, test_probs, test_targets = evaluate_test_set(\n    model, test_loader, best_threshold, DEVICE, CFG)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 14 \u2014 Qualitative Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def denormalize(tensor):\n    mean = np.array([0.485, 0.456, 0.406])\n    std  = np.array([0.229, 0.224, 0.225])\n    img  = tensor.permute(1,2,0).cpu().numpy()\n    return ((img * std + mean).clip(0,1) * 255).astype(np.uint8)\n\n@torch.no_grad()\ndef visualize_predictions(model, test_ds, threshold, device, cfg, n_samples=6):\n    model.eval()\n    indices = np.linspace(0, len(test_ds)-1, n_samples, dtype=int)\n    fig, axes = plt.subplots(n_samples, 5, figsize=(20, 4*n_samples))\n    for ax, t in zip(axes[0], ['Original','GT Overlay','Pred Overlay','Error Map','Prob Heatmap']):\n        ax.set_title(t, fontsize=11, fontweight='bold')\n\n    os.makedirs(f\"{cfg['save_dir']}/overlays\", exist_ok=True)\n\n    for row, idx in enumerate(indices):\n        img_tensor, mask_tensor = test_ds[idx]\n        logit = model(img_tensor.unsqueeze(0).to(device))\n        prob  = torch.sigmoid(logit).squeeze().cpu().numpy()\n        pred  = (prob >= threshold).astype(np.uint8)\n        gt    = mask_tensor.squeeze().numpy().astype(np.uint8)\n        img   = denormalize(img_tensor)\n        m     = compute_metrics(prob.flatten(), gt.flatten(), threshold)\n\n        axes[row,0].imshow(img)\n        axes[row,0].set_ylabel(f'img_{idx}\\nDice={m[\"dice\"]:.3f}', fontsize=8)\n        axes[row,0].axis('off')\n\n        gt_ov = img.copy()\n        gt_ov[gt==1] = (gt_ov[gt==1]*0.5 + np.array([0,200,0])*0.5).astype(np.uint8)\n        axes[row,1].imshow(gt_ov); axes[row,1].axis('off')\n\n        pr_ov = img.copy()\n        pr_ov[pred==1] = (pr_ov[pred==1]*0.5 + np.array([0,200,0])*0.5).astype(np.uint8)\n        axes[row,2].imshow(pr_ov); axes[row,2].axis('off')\n\n        err = img.copy().astype(np.float32)\n        tp_ = (gt.astype(bool) & pred.astype(bool))\n        fp_ = (~gt.astype(bool) & pred.astype(bool))\n        fn_ = (gt.astype(bool) & ~pred.astype(bool))\n        err[tp_]=[0,200,0]; err[fp_]=[0,0,255]; err[fn_]=[255,0,0]\n        axes[row,3].imshow(err.astype(np.uint8))\n        axes[row,3].legend(handles=[\n            mpatches.Patch(color='lime',label='TP'),\n            mpatches.Patch(color='blue',label='FP'),\n            mpatches.Patch(color='red', label='FN')\n        ], loc='lower right', fontsize=7)\n        axes[row,3].axis('off')\n\n        im = axes[row,4].imshow(prob, cmap='hot', vmin=0, vmax=1)\n        plt.colorbar(im, ax=axes[row,4], fraction=0.046, pad=0.04)\n        axes[row,4].axis('off')\n\n        cv2.imwrite(f\"{cfg['save_dir']}/overlays/img_{idx}_overlay.png\",\n                    cv2.cvtColor(pr_ov, cv2.COLOR_RGB2BGR))\n\n    plt.suptitle(f'Qualitative Results \u2014 FIVES | Threshold={threshold:.3f}',\n                 fontsize=13, y=1.01)\n    plt.tight_layout()\n    fig_path = f\"{cfg['save_dir']}/qualitative_results.png\"\n    plt.savefig(fig_path, dpi=100, bbox_inches='tight')\n    plt.show()\n    print(f'\u2705 Saved \u2192 {fig_path}')\n\n\nvisualize_predictions(model, test_ds, best_threshold, DEVICE, CFG, n_samples=6)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 15 \u2014 Thin Vessel Zoom"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@torch.no_grad()\ndef thin_vessel_zoom(model, test_ds, threshold, device, cfg, sample_idx=0, n_patches=4):\n    model.eval()\n    img_tensor, mask_tensor = test_ds[sample_idx]\n    logit = model(img_tensor.unsqueeze(0).to(device))\n    prob  = torch.sigmoid(logit).squeeze().cpu().numpy()\n    pred  = (prob >= threshold).astype(np.uint8)\n    gt    = mask_tensor.squeeze().numpy().astype(np.uint8)\n    img   = denormalize(img_tensor)\n\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n    thin   = gt - cv2.erode(gt, kernel, iterations=1)\n    ys, xs = np.where(thin > 0)\n    if len(ys) == 0:\n        print('\u26a0\ufe0f  No thin vessels found. Try a different sample_idx.')\n        return\n\n    pad  = 48\n    h, w = thin.shape\n    idxs = random.sample(range(len(ys)), min(n_patches, len(ys)))\n    fig, axes = plt.subplots(n_patches, 3, figsize=(9, 3*n_patches))\n    if n_patches == 1: axes = axes[np.newaxis, :]\n\n    for row, i in enumerate(idxs):\n        cy, cx = int(ys[i]), int(xs[i])\n        y0,y1 = max(0,cy-pad), min(h,cy+pad)\n        x0,x1 = max(0,cx-pad), min(w,cx+pad)\n        axes[row,0].imshow(img[y0:y1,x0:x1]); axes[row,0].set_title('Fundus',fontsize=9); axes[row,0].axis('off')\n        axes[row,1].imshow(gt[y0:y1,x0:x1],cmap='gray'); axes[row,1].set_title('GT Mask',fontsize=9); axes[row,1].axis('off')\n        axes[row,2].imshow(pred[y0:y1,x0:x1],cmap='gray'); axes[row,2].set_title('Predicted',fontsize=9); axes[row,2].axis('off')\n\n    plt.suptitle(f'Thin Vessel Zoom \u2014 Test Image {sample_idx}', fontsize=11)\n    plt.tight_layout()\n    plt.savefig(f\"{cfg['save_dir']}/thin_vessel_zoom.png\", dpi=150, bbox_inches='tight')\n    plt.show()\n    print('\u2705 Thin vessel zoom saved.')\n\n\nthin_vessel_zoom(model, test_ds, best_threshold, DEVICE, CFG, sample_idx=0, n_patches=4)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 16 \u2014 Save Outputs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json, shutil\n\nfinal_metrics = {\n    **test_metrics,\n    'threshold': best_threshold,\n    'n_test'   : len(test_ds),\n    'cfg'      : {k: str(v) for k, v in CFG.items()},\n}\nmetrics_path = f\"{CFG['save_dir']}/final_metrics.json\"\nwith open(metrics_path, 'w') as f:\n    json.dump(final_metrics, f, indent=2)\nprint(f'\u2705 Metrics saved \u2192 {metrics_path}')\n\nzip_path = './retinal_segmentation_outputs'\nshutil.make_archive(zip_path, 'zip', CFG['save_dir'])\nprint(f'\u2705 Zipped \u2192 {zip_path}.zip')\n\nprint('\\n\ud83d\udcc1 Output files:')\nfor fp in sorted(Path(CFG['save_dir']).rglob('*')):\n    if fp.is_file():\n        print(f'   {fp.relative_to(CFG[\"save_dir\"])}')\n"
  }
 ]
}